{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<main style=\"font-family: TeX Gyre Termes; font-size: 1.2rem\">\n",
    "\n",
    "### MEX #7 - Geyzson Kristoffer\n",
    "SN:2023-21036\n",
    "\n",
    "https://uvle.upd.edu.ph/mod/assign/view.php?id=547271\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('diabetes_data_upload.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Age                 520 non-null    int64 \n",
      " 1   Gender              520 non-null    object\n",
      " 2   Polyuria            520 non-null    object\n",
      " 3   Polydipsia          520 non-null    object\n",
      " 4   sudden weight loss  520 non-null    object\n",
      " 5   weakness            520 non-null    object\n",
      " 6   Polyphagia          520 non-null    object\n",
      " 7   Genital thrush      520 non-null    object\n",
      " 8   visual blurring     520 non-null    object\n",
      " 9   Itching             520 non-null    object\n",
      " 10  Irritability        520 non-null    object\n",
      " 11  delayed healing     520 non-null    object\n",
      " 12  partial paresis     520 non-null    object\n",
      " 13  muscle stiffness    520 non-null    object\n",
      " 14  Alopecia            520 non-null    object\n",
      " 15  Obesity             520 non-null    object\n",
      " 16  class               520 non-null    object\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 69.2+ KB\n"
     ]
    }
   ],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>520.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.028846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.151466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age\n",
       "count  520.000000\n",
       "mean    48.028846\n",
       "std     12.151466\n",
       "min     16.000000\n",
       "25%     39.000000\n",
       "50%     47.500000\n",
       "75%     57.000000\n",
       "max     90.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>58</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0     40    Male       No        Yes                 No      Yes         No   \n",
       "1     58    Male       No         No                 No      Yes         No   \n",
       "2     41    Male      Yes         No                 No      Yes        Yes   \n",
       "3     45    Male       No         No                Yes      Yes        Yes   \n",
       "4     60    Male      Yes        Yes                Yes      Yes        Yes   \n",
       "..   ...     ...      ...        ...                ...      ...        ...   \n",
       "515   39  Female      Yes        Yes                Yes       No        Yes   \n",
       "516   48  Female      Yes        Yes                Yes      Yes        Yes   \n",
       "517   58  Female      Yes        Yes                Yes      Yes        Yes   \n",
       "518   32  Female       No         No                 No      Yes         No   \n",
       "519   42    Male       No         No                 No       No         No   \n",
       "\n",
       "    Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0               No              No     Yes           No             Yes   \n",
       "1               No             Yes      No           No              No   \n",
       "2               No              No     Yes           No             Yes   \n",
       "3              Yes              No     Yes           No             Yes   \n",
       "4               No             Yes     Yes          Yes             Yes   \n",
       "..             ...             ...     ...          ...             ...   \n",
       "515             No              No     Yes           No             Yes   \n",
       "516             No              No     Yes          Yes             Yes   \n",
       "517             No             Yes      No           No              No   \n",
       "518             No             Yes     Yes           No             Yes   \n",
       "519             No              No      No           No              No   \n",
       "\n",
       "    partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0                No              Yes      Yes     Yes  Positive  \n",
       "1               Yes               No      Yes      No  Positive  \n",
       "2                No              Yes      Yes      No  Positive  \n",
       "3                No               No       No      No  Positive  \n",
       "4               Yes              Yes      Yes     Yes  Positive  \n",
       "..              ...              ...      ...     ...       ...  \n",
       "515             Yes               No       No      No  Positive  \n",
       "516             Yes               No       No      No  Positive  \n",
       "517             Yes              Yes       No     Yes  Positive  \n",
       "518              No               No      Yes      No  Negative  \n",
       "519              No               No       No      No  Negative  \n",
       "\n",
       "[520 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the categorical data to numerical data\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-23 01:09:09,359] A new study created in memory with name: no-name-4b088767-43e2-47d9-9ad2-95c4857ccb23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-23 01:09:09,673] Trial 0 finished with value: 0.9301974448315912 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'tanh', 'solver': 'adam', 'max_iter': 1270, 'batch_size': 76, 'learning_rate_init': 0.0008420695138320996, 'alpha': 0.007457946090759756, 'shuffle': False, 'tol': 0.00892647370554132, 'momentum': 0.0019367939573782054, 'early_stopping': False}. Best is trial 0 with value: 0.9301974448315912.\n",
      "[I 2024-01-23 01:09:09,730] Trial 1 finished with value: 0.8558652729384436 and parameters: {'classifier': 'SVM', 'C': 32.76396330951154, 'kernel': 'sigmoid', 'degree': 10, 'gamma': 'auto'}. Best is trial 0 with value: 0.9301974448315912.\n",
      "[I 2024-01-23 01:09:09,874] Trial 2 finished with value: 0.9639372822299652 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1804, 'batch_size': 35, 'learning_rate_init': 0.005921063087388748, 'alpha': 0.005956597692792088, 'shuffle': True, 'tol': 0.00767902929472082, 'momentum': 0.007507791791996168, 'early_stopping': False}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:09,891] Trial 3 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.007587125801335759}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:09,922] Trial 4 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 53.59418487969658, 'max_iter': 1714}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:09,937] Trial 5 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.00506869830510729}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:09,966] Trial 6 finished with value: 0.9229965156794424 and parameters: {'classifier': 'LogisticRegression', 'C': 4.069344588694385, 'max_iter': 1347}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:09,995] Trial 7 finished with value: 0.9544134727061557 and parameters: {'classifier': 'SVM', 'C': 8.737564044720804, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:10,010] Trial 8 finished with value: 0.9519163763066203 and parameters: {'classifier': 'kNN', 'n_neighbors': 23, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 35}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:10,025] Trial 9 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.007047545469104481}. Best is trial 2 with value: 0.9639372822299652.\n",
      "[I 2024-01-23 01:09:10,905] Trial 10 finished with value: 0.9688734030197445 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1993, 'batch_size': 6, 'learning_rate_init': 0.008262879557098621, 'alpha': 0.0021764230449038157, 'shuffle': True, 'tol': 0.005184793345376614, 'momentum': 0.009520871442243017, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:11,640] Trial 11 finished with value: 0.9615563298490126 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1998, 'batch_size': 6, 'learning_rate_init': 0.00849708103215435, 'alpha': 0.0009315018812420355, 'shuffle': True, 'tol': 0.005565726866184414, 'momentum': 0.00966910364176431, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:13,634] Trial 12 finished with value: 0.9324622531939607 and parameters: {'classifier': 'RandomForest', 'n_estimators': 990, 'max_depth': 19, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:15,490] Trial 13 finished with value: 0.9687572590011616 and parameters: {'classifier': 'XGBoost', 'n_estimators': 123, 'max_depth': 49, 'learning_rate': 0.6860984736111652, 'booster': 'dart', 'reg_alpha': 0.38099564243989253, 'reg_lambda': 0.43219792814379493, 'scale_pos_weight': 874233.4855941748}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:15,554] Trial 14 finished with value: 0.8965737514518002 and parameters: {'classifier': 'XGBoost', 'n_estimators': 19, 'max_depth': 48, 'learning_rate': 0.7008171213986586, 'booster': 'dart', 'reg_alpha': 0.3757614423108571, 'reg_lambda': 0.4125161737627065, 'scale_pos_weight': 922949.8665842335}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:15,609] Trial 15 finished with value: 0.8894308943089431 and parameters: {'classifier': 'XGBoost', 'n_estimators': 70, 'max_depth': 50, 'learning_rate': 0.21221587542682435, 'booster': 'gbtree', 'reg_alpha': 0.8467379631005517, 'reg_lambda': 0.8654830522272403, 'scale_pos_weight': 722931.8766820274}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:35,752] Trial 16 finished with value: 0.8362369337979094 and parameters: {'classifier': 'XGBoost', 'n_estimators': 447, 'max_depth': 1, 'learning_rate': 0.9100948916314545, 'booster': 'dart', 'reg_alpha': 0.05281194980392889, 'reg_lambda': 0.056531049070244976, 'scale_pos_weight': 256035.74520091206}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:36,617] Trial 17 finished with value: 0.942102206736353 and parameters: {'classifier': 'RandomForest', 'n_estimators': 438, 'max_depth': 32, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:36,638] Trial 18 finished with value: 0.8724738675958188 and parameters: {'classifier': 'kNN', 'n_neighbors': 49, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 6}. Best is trial 10 with value: 0.9688734030197445.\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:09:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-23 01:09:36,707] Trial 19 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 261, 'max_depth': 36, 'learning_rate': 0.42631861361095524, 'booster': 'gblinear', 'reg_alpha': 0.47280624233617685, 'reg_lambda': 0.4676454721645695, 'scale_pos_weight': 556288.1769356709}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:38,212] Trial 20 finished with value: 0.9229965156794424 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'relu', 'solver': 'sgd', 'max_iter': 1593, 'batch_size': 3, 'learning_rate_init': 0.009307223780252644, 'alpha': 0.0013760392097948537, 'shuffle': True, 'tol': 0.0006375208766581288, 'momentum': 0.004806378646016513, 'early_stopping': True}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:38,342] Trial 21 finished with value: 0.9664343786295007 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1890, 'batch_size': 37, 'learning_rate_init': 0.005401015571272823, 'alpha': 0.0049134655081644035, 'shuffle': True, 'tol': 0.006577208875266522, 'momentum': 0.009591146423477342, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:38,492] Trial 22 finished with value: 0.966376306620209 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1990, 'batch_size': 40, 'learning_rate_init': 0.00503065927675151, 'alpha': 0.0036501166128192998, 'shuffle': True, 'tol': 0.004198251856961936, 'momentum': 0.009710949683341769, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:38,661] Trial 23 finished with value: 0.9614982578397214 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1814, 'batch_size': 24, 'learning_rate_init': 0.007212682665151899, 'alpha': 0.003634053797493717, 'shuffle': True, 'tol': 0.005164734830359886, 'momentum': 0.006974828021780761, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:09:38,787] Trial 24 finished with value: 0.7814169570267131 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1048, 'batch_size': 67, 'learning_rate_init': 0.002637429204080896, 'alpha': 0.008944082029794905, 'shuffle': False, 'tol': 0.006693159843186507, 'momentum': 0.00717053495516151, 'early_stopping': True}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:43,657] Trial 25 finished with value: 0.966376306620209 and parameters: {'classifier': 'XGBoost', 'n_estimators': 793, 'max_depth': 18, 'learning_rate': 0.5743418613986662, 'booster': 'dart', 'reg_alpha': 0.14097167593572563, 'reg_lambda': 0.8076390835037418, 'scale_pos_weight': 965292.3760363855}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:43,818] Trial 26 finished with value: 0.9614982578397214 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1903, 'batch_size': 96, 'learning_rate_init': 0.0035024372027108574, 'alpha': 0.0035727402124578304, 'shuffle': True, 'tol': 0.0027792151647120797, 'momentum': 0.009709368709184268, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:43,850] Trial 27 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 91.7378664422028, 'max_iter': 1616}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:44,211] Trial 28 finished with value: 0.9012195121951221 and parameters: {'classifier': 'RandomForest', 'n_estimators': 221, 'max_depth': 38, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 14, 'bootstrap': True}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:44,492] Trial 29 finished with value: 0.9614982578397212 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1481, 'batch_size': 19, 'learning_rate_init': 0.007037388930768636, 'alpha': 0.005834480990254135, 'shuffle': True, 'tol': 0.009610880726022598, 'momentum': 0.0044936569693079555, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:44,525] Trial 30 finished with value: 0.9038327526132404 and parameters: {'classifier': 'kNN', 'n_neighbors': 6, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 46}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:44,649] Trial 31 finished with value: 0.956678281068525 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1987, 'batch_size': 47, 'learning_rate_init': 0.004201978109434986, 'alpha': 0.0032102215711840524, 'shuffle': True, 'tol': 0.0034551337243825158, 'momentum': 0.009965852495394745, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:44,765] Trial 32 finished with value: 0.956678281068525 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1872, 'batch_size': 47, 'learning_rate_init': 0.005393706230155891, 'alpha': 0.002555805044154263, 'shuffle': True, 'tol': 0.0036124043189677373, 'momentum': 0.008371968388070047, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,145] Trial 33 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 99.56331814428631, 'kernel': 'linear', 'degree': 1, 'gamma': 'scale'}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,263] Trial 34 finished with value: 0.9664343786295007 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1990, 'batch_size': 32, 'learning_rate_init': 0.006881507668647048, 'alpha': 0.004691592283759556, 'shuffle': True, 'tol': 0.00656659419890422, 'momentum': 0.008257608990261992, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,412] Trial 35 finished with value: 0.8847270615563299 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1790, 'batch_size': 23, 'learning_rate_init': 0.007653825343149253, 'alpha': 0.00513320238713681, 'shuffle': False, 'tol': 0.006789087045019345, 'momentum': 0.008162734973026834, 'early_stopping': True}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,513] Trial 36 finished with value: 0.9567363530778167 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1710, 'batch_size': 62, 'learning_rate_init': 0.00965612730190967, 'alpha': 2.8439754635392264e-05, 'shuffle': True, 'tol': 0.006258281174285544, 'momentum': 0.005620555995517355, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,531] Trial 37 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.0006361856527503972}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,564] Trial 38 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 66.40425282880773, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,597] Trial 39 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 30.464690776619758, 'max_iter': 1917}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,725] Trial 40 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 673, 'max_depth': 2, 'learning_rate': 0.014086573014961967, 'booster': 'gbtree', 'reg_alpha': 0.8478082545167556, 'reg_lambda': 0.15785777724546401, 'scale_pos_weight': 78892.95739299618}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,857] Trial 41 finished with value: 0.9639953542392569 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1986, 'batch_size': 37, 'learning_rate_init': 0.0060600926640201735, 'alpha': 0.004247996966339213, 'shuffle': True, 'tol': 0.004532681074031573, 'momentum': 0.008636225074536364, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:45,973] Trial 42 finished with value: 0.9639953542392569 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1901, 'batch_size': 35, 'learning_rate_init': 0.004868432370352365, 'alpha': 0.0020333938702937595, 'shuffle': True, 'tol': 0.007684963990977517, 'momentum': 0.009077395112455356, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,208] Trial 43 finished with value: 0.9615563298490126 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 2000, 'batch_size': 15, 'learning_rate_init': 0.00654220880379834, 'alpha': 0.004756505444642852, 'shuffle': True, 'tol': 0.0042004177112122554, 'momentum': 0.00898322611304761, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,392] Trial 44 finished with value: 0.9590592334494772 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1870, 'batch_size': 36, 'learning_rate_init': 0.00851147128510515, 'alpha': 0.006498038103494824, 'shuffle': True, 'tol': 0.005843314337467065, 'momentum': 0.009994366962282614, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,427] Trial 45 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.0008011492435892106}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,737] Trial 46 finished with value: 0.9663182346109178 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1714, 'batch_size': 54, 'learning_rate_init': 0.004742406582340339, 'alpha': 0.0027444164228360847, 'shuffle': True, 'tol': 0.0019143256992819216, 'momentum': 0.006374716970403119, 'early_stopping': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:10:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-23 01:10:46,810] Trial 47 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 268, 'max_depth': 43, 'learning_rate': 0.8568285799258977, 'booster': 'gblinear', 'reg_alpha': 0.6082704765845532, 'reg_lambda': 0.6661797594025346, 'scale_pos_weight': 648011.9933979489}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,844] Trial 48 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 75.68024347227815, 'kernel': 'rbf', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:46,877] Trial 49 finished with value: 0.9278745644599304 and parameters: {'classifier': 'kNN', 'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 2}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:10:48,126] Trial 50 finished with value: 0.9614401858304298 and parameters: {'classifier': 'RandomForest', 'n_estimators': 623, 'max_depth': 28, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 10 with value: 0.9688734030197445.\n",
      "[I 2024-01-23 01:12:12,369] Trial 51 finished with value: 0.9759581881533101 and parameters: {'classifier': 'XGBoost', 'n_estimators': 905, 'max_depth': 18, 'learning_rate': 0.562605408864118, 'booster': 'dart', 'reg_alpha': 0.11584891505972716, 'reg_lambda': 0.9212566499674906, 'scale_pos_weight': 959441.679020013}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:13:50,354] Trial 52 finished with value: 0.956678281068525 and parameters: {'classifier': 'XGBoost', 'n_estimators': 984, 'max_depth': 15, 'learning_rate': 0.4569039693092383, 'booster': 'dart', 'reg_alpha': 0.2610895391890079, 'reg_lambda': 0.3157606525892789, 'scale_pos_weight': 833667.0634124465}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:14:56,069] Trial 53 finished with value: 0.9686411149825785 and parameters: {'classifier': 'XGBoost', 'n_estimators': 807, 'max_depth': 24, 'learning_rate': 0.699974165012396, 'booster': 'dart', 'reg_alpha': 0.0015537759970716686, 'reg_lambda': 0.9982337707918263, 'scale_pos_weight': 410915.7048994139}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:16:07,327] Trial 54 finished with value: 0.9616144018583043 and parameters: {'classifier': 'XGBoost', 'n_estimators': 832, 'max_depth': 23, 'learning_rate': 0.6884970973768408, 'booster': 'dart', 'reg_alpha': 0.006244831015209806, 'reg_lambda': 0.9935637926331016, 'scale_pos_weight': 385686.49910686095}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:17:18,043] Trial 55 finished with value: 0.9614982578397211 and parameters: {'classifier': 'XGBoost', 'n_estimators': 839, 'max_depth': 8, 'learning_rate': 0.7106803327891573, 'booster': 'dart', 'reg_alpha': 0.2312804577962408, 'reg_lambda': 0.621394034607845, 'scale_pos_weight': 782564.4022291936}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:18:00,876] Trial 56 finished with value: 0.9638792102206736 and parameters: {'classifier': 'XGBoost', 'n_estimators': 646, 'max_depth': 26, 'learning_rate': 0.5607271345423479, 'booster': 'dart', 'reg_alpha': 0.24974671137594004, 'reg_lambda': 0.991289559983114, 'scale_pos_weight': 415254.376567282}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:19:21,855] Trial 57 finished with value: 0.9613821138211381 and parameters: {'classifier': 'XGBoost', 'n_estimators': 774, 'max_depth': 11, 'learning_rate': 0.798045110641882, 'booster': 'dart', 'reg_alpha': 0.012863532686231142, 'reg_lambda': 0.7451483653445119, 'scale_pos_weight': 577069.747870106}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:20:56,473] Trial 58 finished with value: 0.9494773519163762 and parameters: {'classifier': 'XGBoost', 'n_estimators': 895, 'max_depth': 22, 'learning_rate': 0.4083479654984836, 'booster': 'dart', 'reg_alpha': 0.6411524539466924, 'reg_lambda': 0.5855139969248995, 'scale_pos_weight': 996526.1903824359}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:20:56,551] Trial 59 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 29.381694389129944, 'max_iter': 1469}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:31,649] Trial 60 finished with value: 0.9639953542392566 and parameters: {'classifier': 'XGBoost', 'n_estimators': 572, 'max_depth': 31, 'learning_rate': 0.6091040783549637, 'booster': 'dart', 'reg_alpha': 0.15036948704719832, 'reg_lambda': 0.2775434933693106, 'scale_pos_weight': 249401.39141406753}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:31,798] Trial 61 finished with value: 0.9663182346109178 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1934, 'batch_size': 28, 'learning_rate_init': 0.008009514730377774, 'alpha': 0.004226416746128373, 'shuffle': True, 'tol': 0.007569344483143585, 'momentum': 0.008284835934020383, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:32,835] Trial 62 finished with value: 0.9566202090592334 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1831, 'batch_size': 10, 'learning_rate_init': 0.0034922843018375133, 'alpha': 0.005281291349772757, 'shuffle': True, 'tol': 0.005100840396095663, 'momentum': 0.0027668682279441983, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:21:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-23 01:21:32,950] Trial 63 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 718, 'max_depth': 13, 'learning_rate': 0.28443886639025906, 'booster': 'gblinear', 'reg_alpha': 0.3802344937278706, 'reg_lambda': 0.8908073629141082, 'scale_pos_weight': 876660.3379842278}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:33,062] Trial 64 finished with value: 0.8509291521486644 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1754, 'batch_size': 43, 'learning_rate_init': 0.0065684847479298624, 'alpha': 0.007119648948622502, 'shuffle': False, 'tol': 0.006942807317105397, 'momentum': 0.008976190407071132, 'early_stopping': True}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:33,080] Trial 65 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.009954839049588143}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:33,116] Trial 66 finished with value: 0.9423344947735192 and parameters: {'classifier': 'kNN', 'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'ball_tree', 'leaf_size': 21}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:33,833] Trial 67 finished with value: 0.942218350754936 and parameters: {'classifier': 'RandomForest', 'n_estimators': 357, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:33,952] Trial 68 finished with value: 0.9542973286875724 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1933, 'batch_size': 56, 'learning_rate_init': 0.005574236490546431, 'alpha': 0.00422809879182608, 'shuffle': True, 'tol': 0.004374376123912339, 'momentum': 7.538751027283321e-05, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:34,008] Trial 69 finished with value: 0.956678281068525 and parameters: {'classifier': 'XGBoost', 'n_estimators': 128, 'max_depth': 19, 'learning_rate': 0.9565902711232827, 'booster': 'gbtree', 'reg_alpha': 0.1338258729978049, 'reg_lambda': 0.5377308274525697, 'scale_pos_weight': 725156.0151550935}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:21:34,129] Trial 70 finished with value: 0.956678281068525 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1196, 'batch_size': 29, 'learning_rate_init': 0.008902370212112022, 'alpha': 0.0022510374113778493, 'shuffle': True, 'tol': 0.005981533767439622, 'momentum': 0.007765556336634129, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:22:55,539] Trial 71 finished with value: 0.9662601626016262 and parameters: {'classifier': 'XGBoost', 'n_estimators': 910, 'max_depth': 18, 'learning_rate': 0.5897618893014974, 'booster': 'dart', 'reg_alpha': 0.13073111941029203, 'reg_lambda': 0.8067403474671819, 'scale_pos_weight': 988377.2185830052}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:23:57,040] Trial 72 finished with value: 0.966260162601626 and parameters: {'classifier': 'XGBoost', 'n_estimators': 779, 'max_depth': 23, 'learning_rate': 0.7867424178531154, 'booster': 'dart', 'reg_alpha': 0.11608250339551254, 'reg_lambda': 0.9095036229585921, 'scale_pos_weight': 911384.1416215281}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:24:23,917] Trial 73 finished with value: 0.9663182346109174 and parameters: {'classifier': 'XGBoost', 'n_estimators': 512, 'max_depth': 7, 'learning_rate': 0.5421980041447001, 'booster': 'dart', 'reg_alpha': 0.30386735346010085, 'reg_lambda': 0.7222483270992679, 'scale_pos_weight': 437680.84185651527}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:24:23,970] Trial 74 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 78.38361536355632, 'max_iter': 1603}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:24:24,006] Trial 75 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 49.656765713382114, 'kernel': 'poly', 'degree': 1, 'gamma': 'auto'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:24:24,406] Trial 76 finished with value: 0.9615563298490126 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1845, 'batch_size': 15, 'learning_rate_init': 0.003863712860522123, 'alpha': 0.0014847577156859547, 'shuffle': True, 'tol': 0.00843625181284805, 'momentum': 0.009199598617648753, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:25:55,185] Trial 77 finished with value: 0.9614401858304298 and parameters: {'classifier': 'XGBoost', 'n_estimators': 898, 'max_depth': 29, 'learning_rate': 0.6627210642477879, 'booster': 'dart', 'reg_alpha': 0.1695047937300898, 'reg_lambda': 0.9937414023274386, 'scale_pos_weight': 819240.0787122118}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:25:55,601] Trial 78 finished with value: 0.8584785133565621 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1948, 'batch_size': 40, 'learning_rate_init': 0.007686134851654697, 'alpha': 0.003297334539851494, 'shuffle': False, 'tol': 0.002576710784955372, 'momentum': 0.006171986946369352, 'early_stopping': True}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:58,690] Trial 79 finished with value: 0.9591173054587688 and parameters: {'classifier': 'XGBoost', 'n_estimators': 752, 'max_depth': 16, 'learning_rate': 0.5055790877571525, 'booster': 'dart', 'reg_alpha': 0.054342211083550016, 'reg_lambda': 0.8452671665535111, 'scale_pos_weight': 293679.41798303893}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:58,906] Trial 80 finished with value: 0.9591753774680605 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1369, 'batch_size': 29, 'learning_rate_init': 0.002554683859667539, 'alpha': 0.004627193320773865, 'shuffle': True, 'tol': 0.005126003776597009, 'momentum': 0.009315973213739528, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:58,942] Trial 81 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 60.99406821031971, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:58,977] Trial 82 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 71.35651204509543, 'kernel': 'rbf', 'degree': 7, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:59,202] Trial 83 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 41.462707950236606, 'kernel': 'linear', 'degree': 8, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:59,235] Trial 84 finished with value: 0.8629500580720093 and parameters: {'classifier': 'SVM', 'C': 84.4780208030947, 'kernel': 'sigmoid', 'degree': 4, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:59,254] Trial 85 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.003166606528244093}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:26:59,290] Trial 86 finished with value: 0.9400116144018582 and parameters: {'classifier': 'kNN', 'n_neighbors': 29, 'weights': 'distance', 'algorithm': 'kd_tree', 'leaf_size': 21}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:28:10,830] Trial 87 finished with value: 0.9495354239256677 and parameters: {'classifier': 'XGBoost', 'n_estimators': 838, 'max_depth': 22, 'learning_rate': 0.7678693384672763, 'booster': 'dart', 'reg_alpha': 0.47874451032399584, 'reg_lambda': 0.401449469478711, 'scale_pos_weight': 991172.117558961}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:28:12,554] Trial 88 finished with value: 0.9323461091753774 and parameters: {'classifier': 'RandomForest', 'n_estimators': 960, 'max_depth': 19, 'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:28:12,693] Trial 89 finished with value: 0.9639953542392569 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1764, 'batch_size': 70, 'learning_rate_init': 0.006497831894878292, 'alpha': 0.005644264889381545, 'shuffle': True, 'tol': 0.0036486582821352725, 'momentum': 0.007953284456671636, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,382] Trial 90 finished with value: 0.9639372822299652 and parameters: {'classifier': 'XGBoost', 'n_estimators': 711, 'max_depth': 10, 'learning_rate': 0.3500923117179659, 'booster': 'dart', 'reg_alpha': 0.3435606524844017, 'reg_lambda': 0.7748809979319458, 'scale_pos_weight': 726328.8732228163}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,424] Trial 91 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 67.74436753239526, 'kernel': 'rbf', 'degree': 7, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,461] Trial 92 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 78.27431319552974, 'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,497] Trial 93 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 62.13938865301663, 'kernel': 'rbf', 'degree': 9, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,532] Trial 94 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 88.87913379896469, 'kernel': 'rbf', 'degree': 5, 'gamma': 'scale'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,763] Trial 95 finished with value: 0.9350174216027876 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'tanh', 'solver': 'adam', 'max_iter': 1658, 'batch_size': 52, 'learning_rate_init': 0.0007826587965994204, 'alpha': 0.008509180855394665, 'shuffle': False, 'tol': 0.00821696565019776, 'momentum': 0.0037193266403328026, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,796] Trial 96 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 49.94540297276791, 'kernel': 'rbf', 'degree': 6, 'gamma': 'auto'}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:12,842] Trial 97 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 75.08668613204092, 'max_iter': 1962}. Best is trial 51 with value: 0.9759581881533101.\n",
      "[I 2024-01-23 01:29:13,087] Trial 98 finished with value: 0.9639372822299652 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1862, 'batch_size': 11, 'learning_rate_init': 0.004587080255599628, 'alpha': 0.006457255956182282, 'shuffle': True, 'tol': 0.006263477887175882, 'momentum': 0.00862955864040402, 'early_stopping': False}. Best is trial 51 with value: 0.9759581881533101.\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [01:29:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-01-23 01:29:13,186] Trial 99 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 577, 'max_depth': 45, 'learning_rate': 0.6337874274679839, 'booster': 'gblinear', 'reg_alpha': 0.1915096494054627, 'reg_lambda': 0.9227345843740152, 'scale_pos_weight': 904021.9327590714}. Best is trial 51 with value: 0.9759581881533101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial final score: 0.9759581881533101\n",
      "classifier: XGBoost\n",
      "n_estimators: 905\n",
      "max_depth: 18\n",
      "learning_rate: 0.562605408864118\n",
      "booster: dart\n",
      "reg_alpha: 0.11584891505972716\n",
      "reg_lambda: 0.9212566499674906\n",
      "scale_pos_weight: 959441.679020013\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
    "from ast import literal_eval\n",
    "\n",
    "# Load your data\n",
    "df = diabetes.copy()\n",
    "\n",
    "# Assuming 'class' is the target variable\n",
    "df['class'] = df['class'].map({'Positive': 1, 'Negative': 0})\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "X = X.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (important for models like SVM, kNN, and MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['MLPClassifier', 'RandomForest', 'XGBoost', 'LogisticRegression', 'NaiveBayes', 'SVM', 'kNN'])\n",
    "    \n",
    "    # Hyperparameters spaces for each model\n",
    "    if classifier_name == 'MLPClassifier':\n",
    "        hidden_layer_sizes_str = trial.suggest_categorical('hidden_layer_sizes', ['(50, 50, 50)', '(50, 100, 50)', '(100,)'])\n",
    "        hidden_layer_sizes = eval(hidden_layer_sizes_str)\n",
    "        params = {\n",
    "            'hidden_layer_sizes': hidden_layer_sizes,\n",
    "            'activation': trial.suggest_categorical('activation', ['tanh', 'relu']),\n",
    "            'solver': trial.suggest_categorical('solver', ['sgd', 'adam']),\n",
    "            'max_iter': trial.suggest_int('max_iter', 1000, 2000), \n",
    "            'batch_size': trial.suggest_int('batch_size', 1, 100),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-5, 1e-2),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2),\n",
    "            'shuffle': trial.suggest_categorical('shuffle', [True, False]),\n",
    "            'tol': trial.suggest_float('tol', 1e-5, 1e-2),\n",
    "            'momentum': trial.suggest_float('momentum', 1e-5, 1e-2),\n",
    "            'early_stopping': trial.suggest_categorical('early_stopping', [True, False]),\n",
    "        }\n",
    "        model = MLPClassifier(**params)\n",
    "        \n",
    "    elif classifier_name == 'RandomForest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "            'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "\n",
    "        }\n",
    "        model = RandomForestClassifier(**params)\n",
    "        \n",
    "    elif classifier_name == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0),\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1e-6, 1e6),\n",
    "\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        \n",
    "    elif classifier_name == 'LogisticRegression':\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 1e-8, 1e2),\n",
    "            'max_iter': trial.suggest_int('max_iter', 1000, 2000),\n",
    "        }\n",
    "        model = LogisticRegression(**params)\n",
    "        \n",
    "    elif classifier_name == 'NaiveBayes':\n",
    "        params = {\n",
    "            'var_smoothing': trial.suggest_float('var_smoothing', 1e-8, 1e-2),\n",
    "        }\n",
    "        model = GaussianNB(**params)\n",
    "        \n",
    "    elif classifier_name == 'SVM':\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 1e-8, 1e2),\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'degree': trial.suggest_int('degree', 1, 10),\n",
    "            'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "        }\n",
    "        model = SVC(**params)\n",
    "        \n",
    "    elif classifier_name == 'kNN':\n",
    "        params = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 50),\n",
    "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            'algorithm': trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "            'leaf_size': trial.suggest_int('leaf_size', 1, 50),\n",
    "        }\n",
    "        model = KNeighborsClassifier(**params)\n",
    "\n",
    "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "    precision_scorer = make_scorer(precision_score)\n",
    "    recall_scorer = make_scorer(recall_score)\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    # score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10, scoring=f1_scorer).mean()\n",
    "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10).mean()\n",
    "    return score\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial final score: {best_trial.value}\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Train the best model on the full training data and evaluate it on the test data\n",
    "best_classifier = best_trial.params['classifier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'XGBoost',\n",
       " 'n_estimators': 905,\n",
       " 'max_depth': 18,\n",
       " 'learning_rate': 0.562605408864118,\n",
       " 'booster': 'dart',\n",
       " 'reg_alpha': 0.11584891505972716,\n",
       " 'reg_lambda': 0.9212566499674906,\n",
       " 'scale_pos_weight': 959441.679020013}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the best model hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGBoost'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "best_classifier = best_trial.params['classifier']\n",
    "best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "evaluating model...\n",
      "Test Set Evaluation Metrics:\n",
      "Accuracy: 0.9903846153846154\n",
      "F1 Score: 0.9903442711135019\n",
      "Precision: 0.9905181623931624\n",
      "Recall: 0.9903846153846154\n"
     ]
    }
   ],
   "source": [
    "# Create the best model\n",
    "if best_params['classifier'] == 'MLPClassifier':\n",
    "    model = MLPClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "elif best_params['classifier'] == 'RandomForest':\n",
    "    model = RandomForestClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "elif best_params['classifier'] == 'XGBoost':\n",
    "    model = xgb.XGBClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "elif best_params['classifier'] == 'LogisticRegression':\n",
    "    model = LogisticRegression(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "elif best_params['classifier'] == 'NaiveBayes':\n",
    "    model = GaussianNB()\n",
    "elif best_params['classifier'] == 'SVM':\n",
    "    model = SVC(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "elif best_params['classifier'] == 'kNN':\n",
    "    model = KNeighborsClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
    "\n",
    "print('fitting model...')\n",
    "# Train the model on the full training data\n",
    "model.fit(X_train, y_train, verbose=3)\n",
    "\n",
    "print('evaluating model...')\n",
    "# Evaluate the model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Set Evaluation Metrics:\\nAccuracy: {accuracy}\\nF1 Score: {f1}\\nPrecision: {precision}\\nRecall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-23 01:47:54,962] A new study created in memory with name: no-name-965eeaff-8291-493c-890b-01f3d43afda9\n",
      "[I 2024-01-23 01:47:56,817] Trial 0 finished with value: 0.9352344712573324 and parameters: {'n_estimators': 213, 'max_depth': 5, 'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 0 with value: 0.9352344712573324.\n",
      "[I 2024-01-23 01:47:57,496] Trial 1 finished with value: 0.9078668861150068 and parameters: {'n_estimators': 413, 'max_depth': 35, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 10, 'bootstrap': True}. Best is trial 0 with value: 0.9352344712573324.\n",
      "[I 2024-01-23 01:47:57,687] Trial 2 finished with value: 0.9012327718838293 and parameters: {'n_estimators': 116, 'max_depth': 21, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 14, 'bootstrap': True}. Best is trial 0 with value: 0.9352344712573324.\n",
      "[I 2024-01-23 01:47:58,862] Trial 3 finished with value: 0.915144342299546 and parameters: {'n_estimators': 992, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 0 with value: 0.9352344712573324.\n",
      "[I 2024-01-23 01:47:59,361] Trial 4 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 297, 'max_depth': 33, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:47:59,803] Trial 5 finished with value: 0.9369426838568293 and parameters: {'n_estimators': 257, 'max_depth': 10, 'criterion': 'gini', 'min_samples_split': 13, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:00,376] Trial 6 finished with value: 0.9157166770780177 and parameters: {'n_estimators': 262, 'max_depth': 36, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:02,668] Trial 7 finished with value: 0.9011938121018381 and parameters: {'n_estimators': 860, 'max_depth': 15, 'criterion': 'gini', 'min_samples_split': 7, 'min_samples_leaf': 13, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:05,289] Trial 8 finished with value: 0.9324761815403123 and parameters: {'n_estimators': 971, 'max_depth': 18, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:08,688] Trial 9 finished with value: 0.9204903284435098 and parameters: {'n_estimators': 926, 'max_depth': 37, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:10,588] Trial 10 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 645, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 4 with value: 0.9420946931100435.\n",
      "[I 2024-01-23 01:48:12,753] Trial 11 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 620, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 11 with value: 0.9759284399720268.\n",
      "[I 2024-01-23 01:48:15,228] Trial 12 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 567, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:19,724] Trial 13 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 649, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:22,454] Trial 14 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 573, 'max_depth': 49, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:25,169] Trial 15 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 783, 'max_depth': 28, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:27,528] Trial 16 finished with value: 0.9371987247692897 and parameters: {'n_estimators': 466, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:30,192] Trial 17 finished with value: 0.9517777105522324 and parameters: {'n_estimators': 739, 'max_depth': 27, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:32,015] Trial 18 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 397, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:33,101] Trial 19 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 381, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:33,192] Trial 20 finished with value: 0.9224909148403266 and parameters: {'n_estimators': 35, 'max_depth': 31, 'criterion': 'entropy', 'min_samples_split': 12, 'min_samples_leaf': 11, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:34,424] Trial 21 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 524, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:35,659] Trial 22 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 608, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:37,169] Trial 23 finished with value: 0.9564792816568648 and parameters: {'n_estimators': 723, 'max_depth': 40, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:37,930] Trial 24 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 368, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:38,890] Trial 25 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 470, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:39,762] Trial 26 finished with value: 0.9493991366570205 and parameters: {'n_estimators': 474, 'max_depth': 31, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:40,781] Trial 27 finished with value: 0.9710801316135094 and parameters: {'n_estimators': 543, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:41,868] Trial 28 finished with value: 0.9444522948809105 and parameters: {'n_estimators': 441, 'max_depth': 23, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:42,122] Trial 29 finished with value: 0.906071318153592 and parameters: {'n_estimators': 151, 'max_depth': 3, 'criterion': 'gini', 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:42,980] Trial 30 finished with value: 0.9711120734368018 and parameters: {'n_estimators': 355, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:44,609] Trial 31 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 697, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:46,152] Trial 32 finished with value: 0.970989609194749 and parameters: {'n_estimators': 702, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:47,705] Trial 33 finished with value: 0.9541216798859977 and parameters: {'n_estimators': 820, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:48,683] Trial 34 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 498, 'max_depth': 50, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:49,301] Trial 35 finished with value: 0.9493991366570205 and parameters: {'n_estimators': 323, 'max_depth': 35, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:50,432] Trial 36 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 569, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:51,251] Trial 37 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 414, 'max_depth': 38, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:51,819] Trial 38 finished with value: 0.9493265932984365 and parameters: {'n_estimators': 220, 'max_depth': 33, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': True}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:52,482] Trial 39 finished with value: 0.9248916364781327 and parameters: {'n_estimators': 295, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 12, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:54,273] Trial 40 finished with value: 0.9299752652753852 and parameters: {'n_estimators': 680, 'max_depth': 35, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:55,404] Trial 41 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 568, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:56,520] Trial 42 finished with value: 0.970989609194749 and parameters: {'n_estimators': 513, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 12 with value: 0.9783553974512491.\n",
      "[I 2024-01-23 01:48:58,162] Trial 43 finished with value: 0.9807808518987624 and parameters: {'n_estimators': 587, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:48:59,099] Trial 44 finished with value: 0.9589117745871526 and parameters: {'n_estimators': 424, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:01,441] Trial 45 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 756, 'max_depth': 8, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:02,753] Trial 46 finished with value: 0.978280237834029 and parameters: {'n_estimators': 611, 'max_depth': 37, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:04,839] Trial 47 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 871, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:06,770] Trial 48 finished with value: 0.9759856744042613 and parameters: {'n_estimators': 678, 'max_depth': 16, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:08,087] Trial 49 finished with value: 0.9541143401987545 and parameters: {'n_estimators': 457, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:10,001] Trial 50 finished with value: 0.9348547554355244 and parameters: {'n_estimators': 631, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:11,391] Trial 51 finished with value: 0.9758257863445424 and parameters: {'n_estimators': 574, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:13,217] Trial 52 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 562, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:15,061] Trial 53 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 514, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:16,443] Trial 54 finished with value: 0.9759856744042613 and parameters: {'n_estimators': 656, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:17,855] Trial 55 finished with value: 0.9197713429510049 and parameters: {'n_estimators': 605, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:19,150] Trial 56 finished with value: 0.9541353123230996 and parameters: {'n_estimators': 484, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:20,449] Trial 57 finished with value: 0.961065928062894 and parameters: {'n_estimators': 407, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:22,094] Trial 58 finished with value: 0.9734440606842355 and parameters: {'n_estimators': 781, 'max_depth': 38, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:23,891] Trial 59 finished with value: 0.9444386624438087 and parameters: {'n_estimators': 539, 'max_depth': 40, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': True}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:25,138] Trial 60 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 600, 'max_depth': 33, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:26,153] Trial 61 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 491, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:27,473] Trial 62 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 525, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:28,188] Trial 63 finished with value: 0.9734440606842355 and parameters: {'n_estimators': 338, 'max_depth': 49, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:29,526] Trial 64 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 580, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:30,461] Trial 65 finished with value: 0.9564792816568648 and parameters: {'n_estimators': 449, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:31,216] Trial 66 finished with value: 0.9683406910366275 and parameters: {'n_estimators': 384, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:32,595] Trial 67 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 662, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:33,670] Trial 68 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 546, 'max_depth': 20, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:34,692] Trial 69 finished with value: 0.9564792816568648 and parameters: {'n_estimators': 515, 'max_depth': 46, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:36,470] Trial 70 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 712, 'max_depth': 40, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:37,920] Trial 71 finished with value: 0.978280237834029 and parameters: {'n_estimators': 496, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:39,432] Trial 72 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 472, 'max_depth': 49, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:40,517] Trial 73 finished with value: 0.9734638712988039 and parameters: {'n_estimators': 383, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:41,525] Trial 74 finished with value: 0.9563565284300249 and parameters: {'n_estimators': 446, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 43 with value: 0.9807808518987624.\n",
      "[I 2024-01-23 01:49:43,380] Trial 75 finished with value: 0.9831326497607644 and parameters: {'n_estimators': 634, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:44,819] Trial 76 finished with value: 0.970989609194749 and parameters: {'n_estimators': 598, 'max_depth': 25, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:46,550] Trial 77 finished with value: 0.9251802046403543 and parameters: {'n_estimators': 701, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 13, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:48,326] Trial 78 finished with value: 0.9276176635045182 and parameters: {'n_estimators': 628, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:50,196] Trial 79 finished with value: 0.9517567384278875 and parameters: {'n_estimators': 739, 'max_depth': 36, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:51,819] Trial 80 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 680, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:52,927] Trial 81 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 548, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:53,971] Trial 82 finished with value: 0.978280237834029 and parameters: {'n_estimators': 510, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:54,812] Trial 83 finished with value: 0.9734440606842355 and parameters: {'n_estimators': 424, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:56,083] Trial 84 finished with value: 0.970989609194749 and parameters: {'n_estimators': 636, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:57,082] Trial 85 finished with value: 0.9759871774359704 and parameters: {'n_estimators': 475, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:58,247] Trial 86 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 577, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:49:59,311] Trial 87 finished with value: 0.968570459716776 and parameters: {'n_estimators': 534, 'max_depth': 30, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:00,317] Trial 88 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 495, 'max_depth': 49, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:01,892] Trial 89 finished with value: 0.9588505158648337 and parameters: {'n_estimators': 587, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:02,468] Trial 90 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 284, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:03,642] Trial 91 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 529, 'max_depth': 50, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:04,743] Trial 92 finished with value: 0.978280237834029 and parameters: {'n_estimators': 559, 'max_depth': 48, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:06,036] Trial 93 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 656, 'max_depth': 46, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:06,911] Trial 94 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 429, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:08,141] Trial 95 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 618, 'max_depth': 49, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:08,914] Trial 96 finished with value: 0.9759856744042613 and parameters: {'n_estimators': 394, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:09,905] Trial 97 finished with value: 0.9371582052138665 and parameters: {'n_estimators': 522, 'max_depth': 42, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:10,636] Trial 98 finished with value: 0.9588845097129489 and parameters: {'n_estimators': 356, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n",
      "[I 2024-01-23 01:50:11,657] Trial 99 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 488, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 75 with value: 0.9831326497607644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial final score: 0.9831326497607644\n",
      "n_estimators: 634\n",
      "max_depth: 42\n",
      "criterion: entropy\n",
      "min_samples_split: 6\n",
      "min_samples_leaf: 1\n",
      "bootstrap: False\n"
     ]
    }
   ],
   "source": [
    "def objective2(trial):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "\n",
    "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "    precision_scorer = make_scorer(precision_score)\n",
    "    recall_scorer = make_scorer(recall_score)\n",
    "\n",
    "    # 10-fold cross-validation\n",
    "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10, scoring=f1_scorer).mean()\n",
    "    return score\n",
    "\n",
    "# Create a study object and specify the optimization direction\n",
    "study2 = optuna.create_study(direction='maximize')\n",
    "study2.optimize(objective2, n_trials=100)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_trial2 = study2.best_trial\n",
    "print(f\"Best trial final score: {best_trial2.value}\")\n",
    "for key, value in best_trial2.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Train the best model on the full training data and evaluate it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 634,\n",
       " 'max_depth': 42,\n",
       " 'criterion': 'entropy',\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 1,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_classifier2 = best_trial2.params\n",
    "best_classifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, criterion=&#x27;entropy&#x27;, max_depth=42,\n",
       "                       min_samples_split=6, n_estimators=634)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, criterion=&#x27;entropy&#x27;, max_depth=42,\n",
       "                       min_samples_split=6, n_estimators=634)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=42,\n",
       "                       min_samples_split=6, n_estimators=634)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(**best_classifier2)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Metrics:\n",
      "Accuracy: 0.9903846153846154\n",
      "F1 Score: 0.9904222748776574\n",
      "Precision: 0.9906674208144797\n",
      "Recall: 0.9903846153846154\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = model2.predict(X_test)\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "f1_2 = f1_score(y_test, y_pred2, average='weighted')\n",
    "precision2 = precision_score(y_test, y_pred2, average='weighted')\n",
    "recall2 = recall_score(y_test, y_pred2, average='weighted')\n",
    "\n",
    "print(f\"Test Set Evaluation Metrics:\\nAccuracy: {accuracy2}\\nF1 Score: {f1_2}\\nPrecision: {precision2}\\nRecall: {recall2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
       "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
       "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
       "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
       "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
       "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
       "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
       "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
       "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
       "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
       "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
       "\n",
       "[395 rows x 33 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_scores = pd.read_csv('student-mat.csv', delimiter=';')\n",
    "math_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = math_scores.copy()\n",
    "\n",
    "y = df['G3']\n",
    "X = df.copy().drop('G3', axis=1).copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "X = X.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (important for models like SVM, kNN, and MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     ... higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
       "0    ...    yes       no        no       4         3     4    1    1      3   \n",
       "1    ...    yes      yes        no       5         3     3    1    1      3   \n",
       "2    ...    yes      yes        no       4         3     2    2    3      3   \n",
       "3    ...    yes      yes       yes       3         2     2    1    1      5   \n",
       "4    ...    yes       no        no       4         3     2    1    2      5   \n",
       "..   ...    ...      ...       ...     ...       ...   ...  ...  ...    ...   \n",
       "644  ...    yes      yes        no       5         4     2    1    2      5   \n",
       "645  ...    yes      yes        no       4         3     4    1    1      1   \n",
       "646  ...    yes       no        no       1         1     1    1    1      5   \n",
       "647  ...    yes      yes        no       2         4     5    3    4      2   \n",
       "648  ...    yes      yes        no       4         4     1    3    4      5   \n",
       "\n",
       "    absences  \n",
       "0          4  \n",
       "1          2  \n",
       "2          6  \n",
       "3          0  \n",
       "4          0  \n",
       "..       ...  \n",
       "644        4  \n",
       "645        4  \n",
       "646        6  \n",
       "647        6  \n",
       "648        4  \n",
       "\n",
       "[649 rows x 30 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = student_performance.data.features \n",
    "y = student_performance.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(student_performance.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(student_performance.variables) \n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import piplite\n",
    "# await piplite.install('lazypredict')\n",
    "# import lazypredict\n",
    "\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y= data.target\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
