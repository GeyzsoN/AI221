{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<main style=\"font-family: TeX Gyre Termes; font-size: 1.2rem\">\n",
        "\n",
        "### MEX #7 - Geyzson Kristoffer\n",
        "SN:2023-21036\n",
        "\n",
        "https://uvle.upd.edu.ph/mod/assign/view.php?id=547271\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Polyuria</th>\n",
              "      <th>Polydipsia</th>\n",
              "      <th>sudden weight loss</th>\n",
              "      <th>weakness</th>\n",
              "      <th>Polyphagia</th>\n",
              "      <th>Genital thrush</th>\n",
              "      <th>visual blurring</th>\n",
              "      <th>Itching</th>\n",
              "      <th>Irritability</th>\n",
              "      <th>delayed healing</th>\n",
              "      <th>partial paresis</th>\n",
              "      <th>muscle stiffness</th>\n",
              "      <th>Alopecia</th>\n",
              "      <th>Obesity</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
              "0   40   Male       No        Yes                 No      Yes         No   \n",
              "1   58   Male       No         No                 No      Yes         No   \n",
              "2   41   Male      Yes         No                 No      Yes        Yes   \n",
              "3   45   Male       No         No                Yes      Yes        Yes   \n",
              "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
              "\n",
              "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
              "0             No              No     Yes           No             Yes   \n",
              "1             No             Yes      No           No              No   \n",
              "2             No              No     Yes           No             Yes   \n",
              "3            Yes              No     Yes           No             Yes   \n",
              "4             No             Yes     Yes          Yes             Yes   \n",
              "\n",
              "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
              "0              No              Yes      Yes     Yes  Positive  \n",
              "1             Yes               No      Yes      No  Positive  \n",
              "2              No              Yes      Yes      No  Positive  \n",
              "3              No               No       No      No  Positive  \n",
              "4             Yes              Yes      Yes     Yes  Positive  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "diabetes = pd.read_csv('diabetes_data_upload.csv')\n",
        "diabetes.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 520 entries, 0 to 519\n",
            "Data columns (total 17 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Age                 520 non-null    int64 \n",
            " 1   Gender              520 non-null    object\n",
            " 2   Polyuria            520 non-null    object\n",
            " 3   Polydipsia          520 non-null    object\n",
            " 4   sudden weight loss  520 non-null    object\n",
            " 5   weakness            520 non-null    object\n",
            " 6   Polyphagia          520 non-null    object\n",
            " 7   Genital thrush      520 non-null    object\n",
            " 8   visual blurring     520 non-null    object\n",
            " 9   Itching             520 non-null    object\n",
            " 10  Irritability        520 non-null    object\n",
            " 11  delayed healing     520 non-null    object\n",
            " 12  partial paresis     520 non-null    object\n",
            " 13  muscle stiffness    520 non-null    object\n",
            " 14  Alopecia            520 non-null    object\n",
            " 15  Obesity             520 non-null    object\n",
            " 16  class               520 non-null    object\n",
            "dtypes: int64(1), object(16)\n",
            "memory usage: 69.2+ KB\n"
          ]
        }
      ],
      "source": [
        "diabetes.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-01-23 04:13:03,199] A new study created in memory with name: no-name-373802b0-5de5-46d8-a3ba-862fc63116dc\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-01-23 04:13:04,083] Trial 0 finished with value: 0.9179442508710803 and parameters: {'classifier': 'RandomForest', 'n_estimators': 714, 'max_depth': 13, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 7, 'bootstrap': True}. Best is trial 0 with value: 0.9179442508710803.\n",
            "[I 2024-01-23 04:13:04,111] Trial 1 finished with value: 0.870150987224158 and parameters: {'classifier': 'kNN', 'n_neighbors': 28, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 8}. Best is trial 0 with value: 0.9179442508710803.\n",
            "[I 2024-01-23 04:13:04,124] Trial 2 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 27.595157339340947, 'max_iter': 1996}. Best is trial 2 with value: 0.92061556329849.\n",
            "[I 2024-01-23 04:13:09,391] Trial 3 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 334, 'max_depth': 24, 'learning_rate': 0.0012840005839864727, 'booster': 'dart', 'reg_alpha': 0.9937318537545634, 'reg_lambda': 0.42952362274475325, 'scale_pos_weight': 462376.23478665506}. Best is trial 2 with value: 0.92061556329849.\n",
            "[I 2024-01-23 04:13:09,420] Trial 4 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 87, 'max_depth': 33, 'learning_rate': 0.012497103059991016, 'booster': 'gbtree', 'reg_alpha': 0.6783680116086803, 'reg_lambda': 0.21517235739232524, 'scale_pos_weight': 917579.8056591077}. Best is trial 2 with value: 0.92061556329849.\n",
            "[I 2024-01-23 04:13:14,958] Trial 5 finished with value: 0.9591173054587688 and parameters: {'classifier': 'XGBoost', 'n_estimators': 338, 'max_depth': 23, 'learning_rate': 0.9940632260094652, 'booster': 'dart', 'reg_alpha': 0.5798397611120658, 'reg_lambda': 0.4914104804487928, 'scale_pos_weight': 633309.4550088117}. Best is trial 5 with value: 0.9591173054587688.\n",
            "[I 2024-01-23 04:13:15,882] Trial 6 finished with value: 0.9179442508710803 and parameters: {'classifier': 'RandomForest', 'n_estimators': 870, 'max_depth': 30, 'criterion': 'gini', 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 5 with value: 0.9591173054587688.\n",
            "[I 2024-01-23 04:13:15,905] Trial 7 finished with value: 0.8990127758420442 and parameters: {'classifier': 'kNN', 'n_neighbors': 22, 'weights': 'uniform', 'algorithm': 'brute', 'leaf_size': 45}. Best is trial 5 with value: 0.9591173054587688.\n",
            "[I 2024-01-23 04:13:15,919] Trial 8 finished with value: 0.9686411149825783 and parameters: {'classifier': 'SVM', 'C': 73.51594749868863, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 8 with value: 0.9686411149825783.\n",
            "[I 2024-01-23 04:13:20,941] Trial 9 finished with value: 0.9639953542392566 and parameters: {'classifier': 'XGBoost', 'n_estimators': 313, 'max_depth': 4, 'learning_rate': 0.2876199755500976, 'booster': 'dart', 'reg_alpha': 0.24659677246398276, 'reg_lambda': 0.17079846006509997, 'scale_pos_weight': 676690.2918784912}. Best is trial 8 with value: 0.9686411149825783.\n",
            "[I 2024-01-23 04:13:20,969] Trial 10 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 96.43417346035147, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:20,988] Trial 11 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 90.7267218720897, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,021] Trial 12 finished with value: 0.9685830429732871 and parameters: {'classifier': 'SVM', 'C': 99.54200737713865, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,037] Trial 13 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.00013479211664677287}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,108] Trial 14 finished with value: 0.9469221835075494 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1002, 'batch_size': 76, 'learning_rate_init': 0.0024767269178855855, 'alpha': 0.007138348007408606, 'shuffle': False, 'tol': 0.00795054654016143, 'momentum': 0.0009965656662591794, 'early_stopping': False}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,140] Trial 15 finished with value: 0.9519744483159116 and parameters: {'classifier': 'SVM', 'C': 94.47920457864966, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,160] Trial 16 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 61.94501298972159, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:21,177] Trial 17 finished with value: 0.8557491289198607 and parameters: {'classifier': 'SVM', 'C': 80.9560249298696, 'kernel': 'sigmoid', 'degree': 2, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:22,733] Trial 18 finished with value: 0.925377468060395 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1470, 'batch_size': 1, 'learning_rate_init': 0.00862995805813607, 'alpha': 1.3933523101907971e-05, 'shuffle': True, 'tol': 0.0006177330016998673, 'momentum': 0.009562491701479419, 'early_stopping': True}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:22,749] Trial 19 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.009165371071985104}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:22,766] Trial 20 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 36.67117032298361, 'max_iter': 1973}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:22,796] Trial 21 finished with value: 0.9471544715447155 and parameters: {'classifier': 'SVM', 'C': 69.78571057887373, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,075] Trial 22 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 82.8466649302196, 'kernel': 'linear', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,107] Trial 23 finished with value: 0.9544134727061557 and parameters: {'classifier': 'SVM', 'C': 6.2877245128346, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,138] Trial 24 finished with value: 0.9638211382113824 and parameters: {'classifier': 'SVM', 'C': 82.90986332822709, 'kernel': 'poly', 'degree': 7, 'gamma': 'auto'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,158] Trial 25 finished with value: 0.9663182346109178 and parameters: {'classifier': 'SVM', 'C': 99.12994388372402, 'kernel': 'poly', 'degree': 3, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,190] Trial 26 finished with value: 0.9638211382113824 and parameters: {'classifier': 'SVM', 'C': 63.55851884552162, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,208] Trial 27 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 81.97649644949229, 'kernel': 'rbf', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:23,223] Trial 28 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.003329390336711483}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,108] Trial 29 finished with value: 0.9614401858304298 and parameters: {'classifier': 'RandomForest', 'n_estimators': 979, 'max_depth': 46, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,183] Trial 30 finished with value: 0.5508710801393727 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'relu', 'solver': 'sgd', 'max_iter': 1004, 'batch_size': 97, 'learning_rate_init': 0.00012171273176739359, 'alpha': 0.00964332514629751, 'shuffle': False, 'tol': 0.0027981558399986493, 'momentum': 0.006267733578798022, 'early_stopping': False}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,201] Trial 31 finished with value: 0.9685830429732871 and parameters: {'classifier': 'SVM', 'C': 97.78444586092463, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,219] Trial 32 finished with value: 0.9278745644599304 and parameters: {'classifier': 'kNN', 'n_neighbors': 50, 'weights': 'distance', 'algorithm': 'auto', 'leaf_size': 1}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,238] Trial 33 finished with value: 0.9519744483159116 and parameters: {'classifier': 'SVM', 'C': 89.92001046382018, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,257] Trial 34 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 72.49985847100943, 'max_iter': 1470}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,286] Trial 35 finished with value: 0.9662020905923345 and parameters: {'classifier': 'SVM', 'C': 99.64487348811114, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,834] Trial 36 finished with value: 0.9155052264808363 and parameters: {'classifier': 'RandomForest', 'n_estimators': 637, 'max_depth': 45, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,852] Trial 37 finished with value: 0.8389082462253195 and parameters: {'classifier': 'SVM', 'C': 87.26802061203433, 'kernel': 'sigmoid', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,871] Trial 38 finished with value: 0.9542973286875727 and parameters: {'classifier': 'kNN', 'n_neighbors': 4, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 50}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,889] Trial 39 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 52.37274527985346, 'max_iter': 1770}. Best is trial 10 with value: 0.9710220673635309.\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-23 04:13:24,913] Trial 40 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 39, 'max_depth': 2, 'learning_rate': 0.8146896273322293, 'booster': 'gblinear', 'reg_alpha': 0.07872244467904588, 'reg_lambda': 0.9996731136398155, 'scale_pos_weight': 103776.46166460915}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,931] Trial 41 finished with value: 0.9685830429732871 and parameters: {'classifier': 'SVM', 'C': 99.2835353925193, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,950] Trial 42 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 90.09819764223954, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,969] Trial 43 finished with value: 0.9447154471544718 and parameters: {'classifier': 'SVM', 'C': 89.61001982050523, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:24,987] Trial 44 finished with value: 0.9567363530778163 and parameters: {'classifier': 'SVM', 'C': 75.15985283010198, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:25,214] Trial 45 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 88.9331350739514, 'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:25,285] Trial 46 finished with value: 0.9542973286875724 and parameters: {'classifier': 'XGBoost', 'n_estimators': 565, 'max_depth': 13, 'learning_rate': 0.5191349784387113, 'booster': 'gbtree', 'reg_alpha': 0.9866009840324559, 'reg_lambda': 0.8649399062559022, 'scale_pos_weight': 79369.31396094809}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,134] Trial 47 finished with value: 0.9468641114982578 and parameters: {'classifier': 'RandomForest', 'n_estimators': 759, 'max_depth': 38, 'criterion': 'gini', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,165] Trial 48 finished with value: 0.9470963995354239 and parameters: {'classifier': 'SVM', 'C': 90.73597620423888, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,323] Trial 49 finished with value: 0.9423344947735192 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 100, 50)', 'activation': 'tanh', 'solver': 'adam', 'max_iter': 1259, 'batch_size': 22, 'learning_rate_init': 0.009520102316764527, 'alpha': 0.0017542108464353896, 'shuffle': True, 'tol': 0.009979338714018437, 'momentum': 0.0003880290079186369, 'early_stopping': True}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,339] Trial 50 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.009414374010277098}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,359] Trial 51 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 94.85315003648734, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,378] Trial 52 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 91.66677133378234, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,397] Trial 53 finished with value: 0.9686411149825783 and parameters: {'classifier': 'SVM', 'C': 77.78517424792732, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,416] Trial 54 finished with value: 0.9519744483159116 and parameters: {'classifier': 'SVM', 'C': 91.68475246719163, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,443] Trial 55 finished with value: 0.9447154471544718 and parameters: {'classifier': 'SVM', 'C': 85.09781706637078, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,471] Trial 56 finished with value: 0.9710220673635309 and parameters: {'classifier': 'SVM', 'C': 93.04124133422152, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,490] Trial 57 finished with value: 0.935075493612079 and parameters: {'classifier': 'kNN', 'n_neighbors': 49, 'weights': 'distance', 'algorithm': 'ball_tree', 'leaf_size': 30}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,509] Trial 58 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 91.59310943856241, 'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,782] Trial 59 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 93.93296419487285, 'kernel': 'linear', 'degree': 4, 'gamma': 'auto'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,810] Trial 60 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 19.630739502460585, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,829] Trial 61 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 10.083410339182677, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,848] Trial 62 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 30.854412838358915, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,878] Trial 63 finished with value: 0.9519744483159119 and parameters: {'classifier': 'SVM', 'C': 20.133069442534865, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,896] Trial 64 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 46.013667848859654, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,912] Trial 65 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 95.23655424463293, 'max_iter': 1735}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,926] Trial 66 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.005142837300311034}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:26,945] Trial 67 finished with value: 0.8556910569105691 and parameters: {'classifier': 'SVM', 'C': 19.683965379358327, 'kernel': 'sigmoid', 'degree': 4, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:27,105] Trial 68 finished with value: 0.8842044134727061 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(50, 50, 50)', 'activation': 'tanh', 'solver': 'sgd', 'max_iter': 1211, 'batch_size': 47, 'learning_rate_init': 0.005641571114883129, 'alpha': 0.004217576740048508, 'shuffle': True, 'tol': 0.005155703170113382, 'momentum': 0.004441792517852435, 'early_stopping': True}. Best is trial 10 with value: 0.9710220673635309.\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/opt/homebrew/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [04:13:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: \n",
            "Parameters: { \"max_depth\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "[I 2024-01-23 04:13:27,164] Trial 69 finished with value: 0.5986062717770034 and parameters: {'classifier': 'XGBoost', 'n_estimators': 473, 'max_depth': 50, 'learning_rate': 0.5894205332208391, 'booster': 'gblinear', 'reg_alpha': 0.3469830395472857, 'reg_lambda': 0.0014920764641753737, 'scale_pos_weight': 335004.61313439487}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:27,194] Trial 70 finished with value: 0.9447154471544718 and parameters: {'classifier': 'SVM', 'C': 85.90800760912944, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:27,213] Trial 71 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 13.80223481981487, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 10 with value: 0.9710220673635309.\n",
            "[I 2024-01-23 04:13:27,232] Trial 72 finished with value: 0.9734610917537747 and parameters: {'classifier': 'SVM', 'C': 2.9090105588450754, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,263] Trial 73 finished with value: 0.9544134727061557 and parameters: {'classifier': 'SVM', 'C': 42.37996596667249, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,306] Trial 74 finished with value: 0.9637630662020907 and parameters: {'classifier': 'SVM', 'C': 1.7371851438114965, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,486] Trial 75 finished with value: 0.913124274099884 and parameters: {'classifier': 'RandomForest', 'n_estimators': 182, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,505] Trial 76 finished with value: 0.9470963995354239 and parameters: {'classifier': 'SVM', 'C': 95.43481809713786, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,525] Trial 77 finished with value: 0.9637630662020907 and parameters: {'classifier': 'SVM', 'C': 1.87812231655775, 'kernel': 'poly', 'degree': 5, 'gamma': 'auto'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,543] Trial 78 finished with value: 0.9639372822299652 and parameters: {'classifier': 'kNN', 'n_neighbors': 1, 'weights': 'uniform', 'algorithm': 'auto', 'leaf_size': 20}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,562] Trial 79 finished with value: 0.9567363530778163 and parameters: {'classifier': 'SVM', 'C': 80.45068247790337, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,581] Trial 80 finished with value: 0.966376306620209 and parameters: {'classifier': 'SVM', 'C': 56.89355418540991, 'kernel': 'rbf', 'degree': 10, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,599] Trial 81 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 10.199602932227643, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,618] Trial 82 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 9.852989377604333, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,636] Trial 83 finished with value: 0.9519744483159119 and parameters: {'classifier': 'SVM', 'C': 18.48318881855576, 'kernel': 'poly', 'degree': 6, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,656] Trial 84 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 5.449534916151092, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,674] Trial 85 finished with value: 0.92061556329849 and parameters: {'classifier': 'LogisticRegression', 'C': 94.73600722461042, 'max_iter': 1668}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,693] Trial 86 finished with value: 0.8531939605110338 and parameters: {'classifier': 'SVM', 'C': 67.17937770043625, 'kernel': 'sigmoid', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,713] Trial 87 finished with value: 0.9544134727061557 and parameters: {'classifier': 'SVM', 'C': 14.741488370300395, 'kernel': 'poly', 'degree': 4, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,729] Trial 88 finished with value: 0.8939024390243903 and parameters: {'classifier': 'NaiveBayes', 'var_smoothing': 0.0065635942890983805}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,804] Trial 89 finished with value: 0.9639953542392569 and parameters: {'classifier': 'MLPClassifier', 'hidden_layer_sizes': '(100,)', 'activation': 'relu', 'solver': 'adam', 'max_iter': 1273, 'batch_size': 53, 'learning_rate_init': 0.005700622685068756, 'alpha': 0.00505394857349118, 'shuffle': False, 'tol': 0.0056091758437743205, 'momentum': 0.00968148848388958, 'early_stopping': False}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,834] Trial 90 finished with value: 0.9638211382113824 and parameters: {'classifier': 'SVM', 'C': 27.704642683069313, 'kernel': 'poly', 'degree': 7, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,853] Trial 91 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 29.41524851447025, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,871] Trial 92 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 32.428161703792775, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,891] Trial 93 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 24.70164581031176, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:27,975] Trial 94 finished with value: 0.9639372822299652 and parameters: {'classifier': 'XGBoost', 'n_estimators': 459, 'max_depth': 20, 'learning_rate': 0.21262116901970451, 'booster': 'gbtree', 'reg_alpha': 0.004478368589993398, 'reg_lambda': 0.7087295921203218, 'scale_pos_weight': 995491.8979060121}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:28,104] Trial 95 finished with value: 0.9182346109175377 and parameters: {'classifier': 'SVM', 'C': 38.30714314119352, 'kernel': 'linear', 'degree': 6, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:29,151] Trial 96 finished with value: 0.9253193960511034 and parameters: {'classifier': 'RandomForest', 'n_estimators': 959, 'max_depth': 36, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 8, 'bootstrap': True}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:29,168] Trial 97 finished with value: 0.96869918699187 and parameters: {'classifier': 'SVM', 'C': 6.736812205057969, 'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:29,188] Trial 98 finished with value: 0.9567363530778163 and parameters: {'classifier': 'SVM', 'C': 86.71665705653152, 'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 72 with value: 0.9734610917537747.\n",
            "[I 2024-01-23 04:13:29,207] Trial 99 finished with value: 0.9400696864111499 and parameters: {'classifier': 'kNN', 'n_neighbors': 33, 'weights': 'distance', 'algorithm': 'brute', 'leaf_size': 32}. Best is trial 72 with value: 0.9734610917537747.\n"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
        "from ast import literal_eval\n",
        "\n",
        "df = diabetes.copy()\n",
        "\n",
        "df['class'] = df['class'].map({'Positive': 1, 'Negative': 0})\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# 1a.\n",
        "# encoding the labels and splitting the data into train and test sets\n",
        "le = LabelEncoder()\n",
        "X = X.apply(lambda col: le.fit_transform(col.astype(str)), axis=0, result_type='expand')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# running optuna\n",
        "def objective(trial):\n",
        "    classifier_name = trial.suggest_categorical('classifier', ['MLPClassifier', 'RandomForest', 'XGBoost', 'LogisticRegression', 'NaiveBayes', 'SVM', 'kNN'])\n",
        "    \n",
        "    if classifier_name == 'MLPClassifier':\n",
        "        hidden_layer_sizes_str = trial.suggest_categorical('hidden_layer_sizes', ['(50, 50, 50)', '(50, 100, 50)', '(100,)'])\n",
        "        hidden_layer_sizes = eval(hidden_layer_sizes_str)\n",
        "        params = {\n",
        "            'hidden_layer_sizes': hidden_layer_sizes,\n",
        "            'activation': trial.suggest_categorical('activation', ['tanh', 'relu']),\n",
        "            'solver': trial.suggest_categorical('solver', ['sgd', 'adam']),\n",
        "            'max_iter': trial.suggest_int('max_iter', 1000, 2000), \n",
        "            'batch_size': trial.suggest_int('batch_size', 1, 100),\n",
        "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-5, 1e-2),\n",
        "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2),\n",
        "            'shuffle': trial.suggest_categorical('shuffle', [True, False]),\n",
        "            'tol': trial.suggest_float('tol', 1e-5, 1e-2),\n",
        "            'momentum': trial.suggest_float('momentum', 1e-5, 1e-2),\n",
        "            'early_stopping': trial.suggest_categorical('early_stopping', [True, False]),\n",
        "        }\n",
        "        model = MLPClassifier(**params)\n",
        "        \n",
        "    elif classifier_name == 'RandomForest':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "            'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
        "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "\n",
        "        }\n",
        "        model = RandomForestClassifier(**params)\n",
        "        \n",
        "    elif classifier_name == 'XGBoost':\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
        "            'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0),\n",
        "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
        "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0),\n",
        "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0),\n",
        "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1e-6, 1e6),\n",
        "\n",
        "        }\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        \n",
        "    elif classifier_name == 'LogisticRegression':\n",
        "        params = {\n",
        "            'C': trial.suggest_float('C', 1e-8, 1e2),\n",
        "            'max_iter': trial.suggest_int('max_iter', 1000, 2000),\n",
        "        }\n",
        "        model = LogisticRegression(**params)\n",
        "        \n",
        "    elif classifier_name == 'NaiveBayes':\n",
        "        params = {\n",
        "            'var_smoothing': trial.suggest_float('var_smoothing', 1e-8, 1e-2),\n",
        "        }\n",
        "        model = GaussianNB(**params)\n",
        "        \n",
        "    elif classifier_name == 'SVM':\n",
        "        params = {\n",
        "            'C': trial.suggest_float('C', 1e-8, 1e2),\n",
        "            'kernel': trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "            'degree': trial.suggest_int('degree', 1, 10),\n",
        "            'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
        "        }\n",
        "        model = SVC(**params)\n",
        "        \n",
        "    elif classifier_name == 'kNN':\n",
        "        params = {\n",
        "            'n_neighbors': trial.suggest_int('n_neighbors', 1, 50),\n",
        "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
        "            'algorithm': trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "            'leaf_size': trial.suggest_int('leaf_size', 1, 50),\n",
        "        }\n",
        "        model = KNeighborsClassifier(**params)\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    precision_scorer = make_scorer(precision_score)\n",
        "    recall_scorer = make_scorer(recall_score)\n",
        "\n",
        "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10).mean()\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial final score: 0.9734610917537747\n",
            "classifier: SVM\n",
            "C: 2.9090105588450754\n",
            "kernel: poly\n",
            "degree: 5\n",
            "gamma: scale\n"
          ]
        }
      ],
      "source": [
        "best_trial = study.best_trial\n",
        "print(f\"Best trial final score: {best_trial.value}\")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "best_classifier = best_trial.params['classifier']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'classifier': 'SVM',\n",
              " 'C': 2.9090105588450754,\n",
              " 'kernel': 'poly',\n",
              " 'degree': 5,\n",
              " 'gamma': 'scale'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = study.best_trial.params\n",
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of the and F1-score of the best model in the test data \n",
            "Test Set Evaluation Metrics:\n",
            "Accuracy: 0.9807692307692307\n",
            "F1 Score: 0.980602297008547\n",
            "Precision: 0.9812961011591148\n",
            "Recall: 0.9807692307692307\n"
          ]
        }
      ],
      "source": [
        "if best_params['classifier'] == 'MLPClassifier':\n",
        "    model = MLPClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "elif best_params['classifier'] == 'RandomForest':\n",
        "    model = RandomForestClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "elif best_params['classifier'] == 'XGBoost':\n",
        "    model = xgb.XGBClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "elif best_params['classifier'] == 'LogisticRegression':\n",
        "    model = LogisticRegression(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "elif best_params['classifier'] == 'NaiveBayes':\n",
        "    model = GaussianNB()\n",
        "elif best_params['classifier'] == 'SVM':\n",
        "    model = SVC(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "elif best_params['classifier'] == 'kNN':\n",
        "    model = KNeighborsClassifier(**{k: v for k, v in best_params.items() if k != 'classifier'})\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print('The accuracy of the and F1-score of the best model in the test data ')\n",
        "print(f\"Test Set Evaluation Metrics:\\nAccuracy: {accuracy}\\nF1 Score: {f1}\\nPrecision: {precision}\\nRecall: {recall}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-01-23 04:17:31,795] A new study created in memory with name: no-name-041dc1fb-a486-4389-b543-b6fe4a02ac25\n",
            "[I 2024-01-23 04:17:31,914] Trial 0 finished with value: 0.9468575229369947 and parameters: {'n_estimators': 69, 'max_depth': 16, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:32,922] Trial 1 finished with value: 0.8937037041242073 and parameters: {'n_estimators': 969, 'max_depth': 1, 'criterion': 'gini', 'min_samples_split': 7, 'min_samples_leaf': 13, 'bootstrap': True}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:33,295] Trial 2 finished with value: 0.915081379664103 and parameters: {'n_estimators': 400, 'max_depth': 21, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:33,429] Trial 3 finished with value: 0.9420767735497775 and parameters: {'n_estimators': 90, 'max_depth': 49, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:34,023] Trial 4 finished with value: 0.9444386624438087 and parameters: {'n_estimators': 660, 'max_depth': 50, 'criterion': 'gini', 'min_samples_split': 4, 'min_samples_leaf': 5, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:34,087] Trial 5 finished with value: 0.9153006353294927 and parameters: {'n_estimators': 52, 'max_depth': 29, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 14, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:34,870] Trial 6 finished with value: 0.9156571237145148 and parameters: {'n_estimators': 693, 'max_depth': 24, 'criterion': 'gini', 'min_samples_split': 8, 'min_samples_leaf': 9, 'bootstrap': True}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:35,308] Trial 7 finished with value: 0.9250992205872816 and parameters: {'n_estimators': 481, 'max_depth': 35, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 11, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:35,973] Trial 8 finished with value: 0.9395264252291453 and parameters: {'n_estimators': 697, 'max_depth': 12, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:36,398] Trial 9 finished with value: 0.8988255920865594 and parameters: {'n_estimators': 389, 'max_depth': 44, 'criterion': 'gini', 'min_samples_split': 7, 'min_samples_leaf': 14, 'bootstrap': True}. Best is trial 0 with value: 0.9468575229369947.\n",
            "[I 2024-01-23 04:17:36,658] Trial 10 finished with value: 0.958714130200892 and parameters: {'n_estimators': 279, 'max_depth': 13, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 10 with value: 0.958714130200892.\n",
            "[I 2024-01-23 04:17:36,866] Trial 11 finished with value: 0.958714130200892 and parameters: {'n_estimators': 230, 'max_depth': 12, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 10 with value: 0.958714130200892.\n",
            "[I 2024-01-23 04:17:37,116] Trial 12 finished with value: 0.9492360968322066 and parameters: {'n_estimators': 259, 'max_depth': 7, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 10 with value: 0.958714130200892.\n",
            "[I 2024-01-23 04:17:37,350] Trial 13 finished with value: 0.9636269781288869 and parameters: {'n_estimators': 230, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:37,541] Trial 14 finished with value: 0.884250831957256 and parameters: {'n_estimators': 253, 'max_depth': 2, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:37,730] Trial 15 finished with value: 0.9541216798859977 and parameters: {'n_estimators': 195, 'max_depth': 18, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:38,103] Trial 16 finished with value: 0.9492360968322066 and parameters: {'n_estimators': 384, 'max_depth': 8, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:38,621] Trial 17 finished with value: 0.958714130200892 and parameters: {'n_estimators': 570, 'max_depth': 29, 'criterion': 'entropy', 'min_samples_split': 12, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:39,705] Trial 18 finished with value: 0.934611649161283 and parameters: {'n_estimators': 895, 'max_depth': 8, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 6, 'bootstrap': True}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:39,828] Trial 19 finished with value: 0.9636075417829199 and parameters: {'n_estimators': 137, 'max_depth': 15, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:40,004] Trial 20 finished with value: 0.9541353123230996 and parameters: {'n_estimators': 160, 'max_depth': 38, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:40,296] Trial 21 finished with value: 0.961255743920918 and parameters: {'n_estimators': 298, 'max_depth': 15, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:40,343] Trial 22 finished with value: 0.9466775001482374 and parameters: {'n_estimators': 11, 'max_depth': 19, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:40,653] Trial 23 finished with value: 0.9468575229369947 and parameters: {'n_estimators': 326, 'max_depth': 24, 'criterion': 'entropy', 'min_samples_split': 9, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:40,797] Trial 24 finished with value: 0.9303786529157223 and parameters: {'n_estimators': 145, 'max_depth': 5, 'criterion': 'entropy', 'min_samples_split': 12, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:41,289] Trial 25 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 506, 'max_depth': 15, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:41,458] Trial 26 finished with value: 0.9367438176061066 and parameters: {'n_estimators': 143, 'max_depth': 10, 'criterion': 'gini', 'min_samples_split': 12, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:41,706] Trial 27 finished with value: 0.9468575229369947 and parameters: {'n_estimators': 291, 'max_depth': 21, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:42,038] Trial 28 finished with value: 0.9395264252291453 and parameters: {'n_estimators': 364, 'max_depth': 29, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 7, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:42,149] Trial 29 finished with value: 0.9517431059907857 and parameters: {'n_estimators': 94, 'max_depth': 16, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:42,533] Trial 30 finished with value: 0.9254040688470617 and parameters: {'n_estimators': 449, 'max_depth': 4, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 9, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:42,731] Trial 31 finished with value: 0.961065928062894 and parameters: {'n_estimators': 209, 'max_depth': 14, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:42,909] Trial 32 finished with value: 0.9563565284300249 and parameters: {'n_estimators': 186, 'max_depth': 15, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,198] Trial 33 finished with value: 0.958714130200892 and parameters: {'n_estimators': 318, 'max_depth': 18, 'criterion': 'entropy', 'min_samples_split': 12, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,319] Trial 34 finished with value: 0.9539058384859601 and parameters: {'n_estimators': 97, 'max_depth': 10, 'criterion': 'gini', 'min_samples_split': 11, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,495] Trial 35 finished with value: 0.9517567384278875 and parameters: {'n_estimators': 187, 'max_depth': 22, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,556] Trial 36 finished with value: 0.900844576507612 and parameters: {'n_estimators': 56, 'max_depth': 1, 'criterion': 'entropy', 'min_samples_split': 13, 'min_samples_leaf': 12, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,769] Trial 37 finished with value: 0.9515590940416269 and parameters: {'n_estimators': 225, 'max_depth': 13, 'criterion': 'gini', 'min_samples_split': 11, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:43,915] Trial 38 finished with value: 0.9322219816821681 and parameters: {'n_estimators': 109, 'max_depth': 26, 'criterion': 'entropy', 'min_samples_split': 12, 'min_samples_leaf': 5, 'bootstrap': True}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:44,285] Trial 39 finished with value: 0.9400720433705455 and parameters: {'n_estimators': 433, 'max_depth': 5, 'criterion': 'gini', 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 13 with value: 0.9636269781288869.\n",
            "[I 2024-01-23 04:17:44,602] Trial 40 finished with value: 0.9783538944195402 and parameters: {'n_estimators': 328, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 40 with value: 0.9783538944195402.\n",
            "[I 2024-01-23 04:17:44,908] Trial 41 finished with value: 0.9783538944195402 and parameters: {'n_estimators': 343, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 40 with value: 0.9783538944195402.\n",
            "[I 2024-01-23 04:17:45,248] Trial 42 finished with value: 0.980707195313251 and parameters: {'n_estimators': 340, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:45,750] Trial 43 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 555, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:46,274] Trial 44 finished with value: 0.9783538944195402 and parameters: {'n_estimators': 580, 'max_depth': 10, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:46,801] Trial 45 finished with value: 0.9592601997332914 and parameters: {'n_estimators': 599, 'max_depth': 6, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:47,673] Trial 46 finished with value: 0.9711154336250228 and parameters: {'n_estimators': 748, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:48,167] Trial 47 finished with value: 0.9517567384278875 and parameters: {'n_estimators': 533, 'max_depth': 8, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:48,638] Trial 48 finished with value: 0.8795741692508814 and parameters: {'n_estimators': 628, 'max_depth': 2, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:48,981] Trial 49 finished with value: 0.9008125435715375 and parameters: {'n_estimators': 443, 'max_depth': 3, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 10, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:49,651] Trial 50 finished with value: 0.9517567384278875 and parameters: {'n_estimators': 788, 'max_depth': 9, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:50,464] Trial 51 finished with value: 0.9734773486707613 and parameters: {'n_estimators': 722, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:51,252] Trial 52 finished with value: 0.9711154336250228 and parameters: {'n_estimators': 687, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:52,003] Trial 53 finished with value: 0.9543106764216172 and parameters: {'n_estimators': 546, 'max_depth': 7, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:52,927] Trial 54 finished with value: 0.9686609821355363 and parameters: {'n_estimators': 810, 'max_depth': 17, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:53,319] Trial 55 finished with value: 0.9588505158648337 and parameters: {'n_estimators': 349, 'max_depth': 13, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:53,853] Trial 56 finished with value: 0.9636075417829199 and parameters: {'n_estimators': 480, 'max_depth': 12, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': True}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:54,744] Trial 57 finished with value: 0.9471018412278696 and parameters: {'n_estimators': 976, 'max_depth': 6, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:55,121] Trial 58 finished with value: 0.9735312229147748 and parameters: {'n_estimators': 415, 'max_depth': 9, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:55,498] Trial 59 finished with value: 0.9685385178934836 and parameters: {'n_estimators': 414, 'max_depth': 38, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:55,916] Trial 60 finished with value: 0.9541353123230996 and parameters: {'n_estimators': 475, 'max_depth': 9, 'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:56,504] Trial 61 finished with value: 0.9664028668689124 and parameters: {'n_estimators': 632, 'max_depth': 7, 'criterion': 'entropy', 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:56,863] Trial 62 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 379, 'max_depth': 11, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:57,186] Trial 63 finished with value: 0.9328948128021789 and parameters: {'n_estimators': 377, 'max_depth': 4, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:57,503] Trial 64 finished with value: 0.9783538944195402 and parameters: {'n_estimators': 339, 'max_depth': 9, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:57,792] Trial 65 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 339, 'max_depth': 12, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:58,047] Trial 66 finished with value: 0.9735665249262884 and parameters: {'n_estimators': 258, 'max_depth': 19, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:58,371] Trial 67 finished with value: 0.970989609194749 and parameters: {'n_estimators': 343, 'max_depth': 13, 'criterion': 'gini', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 42 with value: 0.980707195313251.\n",
            "[I 2024-01-23 04:17:58,631] Trial 68 finished with value: 0.9807808518987624 and parameters: {'n_estimators': 290, 'max_depth': 32, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:17:58,903] Trial 69 finished with value: 0.9373782482029196 and parameters: {'n_estimators': 294, 'max_depth': 21, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 8, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:17:59,375] Trial 70 finished with value: 0.9468575229369947 and parameters: {'n_estimators': 512, 'max_depth': 34, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 4, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:17:59,615] Trial 71 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 253, 'max_depth': 36, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:17:59,877] Trial 72 finished with value: 0.9685385178934836 and parameters: {'n_estimators': 274, 'max_depth': 35, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:00,393] Trial 73 finished with value: 0.9225340347072656 and parameters: {'n_estimators': 582, 'max_depth': 42, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 13, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:00,621] Trial 74 finished with value: 0.970791782337893 and parameters: {'n_estimators': 233, 'max_depth': 32, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:00,922] Trial 75 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 310, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:01,221] Trial 76 finished with value: 0.970989609194749 and parameters: {'n_estimators': 315, 'max_depth': 41, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:01,447] Trial 77 finished with value: 0.9420946931100435 and parameters: {'n_estimators': 259, 'max_depth': 47, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 6, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:01,733] Trial 78 finished with value: 0.970989609194749 and parameters: {'n_estimators': 305, 'max_depth': 36, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:02,098] Trial 79 finished with value: 0.9517567384278875 and parameters: {'n_estimators': 395, 'max_depth': 31, 'criterion': 'gini', 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:02,282] Trial 80 finished with value: 0.9734739884825405 and parameters: {'n_estimators': 170, 'max_depth': 38, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:02,569] Trial 81 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 281, 'max_depth': 40, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 68 with value: 0.9807808518987624.\n",
            "[I 2024-01-23 04:18:02,776] Trial 82 finished with value: 0.9831326497607644 and parameters: {'n_estimators': 209, 'max_depth': 27, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:02,994] Trial 83 finished with value: 0.9734739884825405 and parameters: {'n_estimators': 222, 'max_depth': 28, 'criterion': 'entropy', 'min_samples_split': 7, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:03,320] Trial 84 finished with value: 0.9685385178934836 and parameters: {'n_estimators': 352, 'max_depth': 26, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:03,515] Trial 85 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 201, 'max_depth': 32, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:03,828] Trial 86 finished with value: 0.9685385178934836 and parameters: {'n_estimators': 331, 'max_depth': 36, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:04,081] Trial 87 finished with value: 0.9541216798859977 and parameters: {'n_estimators': 278, 'max_depth': 28, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:04,320] Trial 88 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 244, 'max_depth': 24, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:04,664] Trial 89 finished with value: 0.968570459716776 and parameters: {'n_estimators': 368, 'max_depth': 44, 'criterion': 'entropy', 'min_samples_split': 8, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:04,798] Trial 90 finished with value: 0.9637481342075416 and parameters: {'n_estimators': 118, 'max_depth': 31, 'criterion': 'gini', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:05,383] Trial 91 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 615, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:05,977] Trial 92 finished with value: 0.9783553974512491 and parameters: {'n_estimators': 628, 'max_depth': 33, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:06,575] Trial 93 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 614, 'max_depth': 34, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:07,072] Trial 94 finished with value: 0.9710801316135094 and parameters: {'n_estimators': 542, 'max_depth': 39, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:07,727] Trial 95 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 688, 'max_depth': 37, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:08,298] Trial 96 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 634, 'max_depth': 43, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:08,818] Trial 97 finished with value: 0.9759856744042613 and parameters: {'n_estimators': 562, 'max_depth': 33, 'criterion': 'entropy', 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:09,244] Trial 98 finished with value: 0.9759284399720268 and parameters: {'n_estimators': 455, 'max_depth': 30, 'criterion': 'entropy', 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n",
            "[I 2024-01-23 04:18:09,866] Trial 99 finished with value: 0.9685385178934836 and parameters: {'n_estimators': 668, 'max_depth': 40, 'criterion': 'entropy', 'min_samples_split': 6, 'min_samples_leaf': 2, 'bootstrap': False}. Best is trial 82 with value: 0.9831326497607644.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial final score: 0.9831326497607644\n",
            "n_estimators: 209\n",
            "max_depth: 27\n",
            "criterion: entropy\n",
            "min_samples_split: 6\n",
            "min_samples_leaf: 1\n",
            "bootstrap: False\n"
          ]
        }
      ],
      "source": [
        "def objective2(trial):\n",
        "\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
        "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
        "\n",
        "    }\n",
        "    model = RandomForestClassifier(**params)\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    precision_scorer = make_scorer(precision_score)\n",
        "    recall_scorer = make_scorer(recall_score)\n",
        "\n",
        "    score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=10, scoring=f1_scorer).mean()\n",
        "    return score\n",
        "\n",
        "study2 = optuna.create_study(direction='maximize')\n",
        "study2.optimize(objective2, n_trials=100)\n",
        "\n",
        "best_trial2 = study2.best_trial\n",
        "print(f\"Best trial final score: {best_trial2.value}\")\n",
        "for key, value in best_trial2.params.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 209,\n",
              " 'max_depth': 27,\n",
              " 'criterion': 'entropy',\n",
              " 'min_samples_split': 6,\n",
              " 'min_samples_leaf': 1,\n",
              " 'bootstrap': False}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_classifier2 = best_trial2.params\n",
        "best_classifier2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, criterion=&#x27;entropy&#x27;, max_depth=27,\n",
              "                       min_samples_split=6, n_estimators=209)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, criterion=&#x27;entropy&#x27;, max_depth=27,\n",
              "                       min_samples_split=6, n_estimators=209)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=27,\n",
              "                       min_samples_split=6, n_estimators=209)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = RandomForestClassifier(**best_classifier2)\n",
        "model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The F1-Score of a better RF model in the test data is \n",
            " 0.9904222748776574\n",
            "\n",
            "Test Set Evaluation Metrics:\n",
            "Accuracy: 0.9903846153846154\n",
            "F1 Score: 0.9904222748776574\n",
            "Precision: 0.9906674208144797\n",
            "Recall: 0.9903846153846154\n"
          ]
        }
      ],
      "source": [
        "model2.fit(X_train, y_train)\n",
        "\n",
        "y_pred2 = model2.predict(X_test)\n",
        "accuracy2 = accuracy_score(y_test, y_pred2)\n",
        "f1_2 = f1_score(y_test, y_pred2, average='weighted')\n",
        "precision2 = precision_score(y_test, y_pred2, average='weighted')\n",
        "recall2 = recall_score(y_test, y_pred2, average='weighted')\n",
        "\n",
        "print('The F1-Score of a better RF model in the test data is \\n', f1_2)\n",
        "print()\n",
        "print(f\"Test Set Evaluation Metrics:\\nAccuracy: {accuracy2}\\nF1 Score: {f1_2}\\nPrecision: {precision2}\\nRecall: {recall2}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
